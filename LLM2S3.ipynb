{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c92f3a-d9d8-427b-9e75-31afe927965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from ftlangdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a855c0-a83a-4d1a-896c-b8140944fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(text):\n",
    "    text = text.lower()\n",
    "    res = detect(text=text.replace('\\n', ' '), low_memory=False)\n",
    "    if res['score'] > 0.5: return res['lang']\n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16cf47b0-0d45-4744-be1b-bab72deac819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_json(\"data/subtaskA_train_multilingual.jsonl\", lines=True)\n",
    "train['language'] = [get_language(text) for text in train['text']]\n",
    "\n",
    "file = \"predictions/s5_train_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "train[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']] = temp[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']]\n",
    "file = \"predictions/binoculars_train_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "train['binoculars'] = 1-temp['probs'] #change to higher number represent \"machine\"\n",
    "file = \"predictions/falcon_train_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "train['falcon'] = temp['probs']\n",
    "file = \"predictions/mistral_train_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "train['mistral'] = temp['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008542fd-f0e5-4140-8a3b-72943fbfcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_json(\"data/subtaskA_dev_multilingual.jsonl\", lines=True)\n",
    "dev['language'] = [get_language(text) for text in dev['text']]\n",
    "\n",
    "file = \"predictions/s5_dev_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "dev[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']] = temp[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']]\n",
    "file = \"predictions/binoculars_dev_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "dev['binoculars'] = 1-temp['probs'] #change to higher number represent \"machine\"\n",
    "file = \"predictions/falcon_dev_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "dev['falcon'] = temp['probs']\n",
    "file = \"predictions/mistral_dev_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "dev['mistral'] = temp['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b5932a-a901-4659-9a91-a3d3a07160e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimal classification threshold calculations\n",
    "languages = ['en', 'bg', 'zh', 'id', 'ur', 'ru', 'de', 'ar']\n",
    "auc_dict = {}\n",
    "for model in [x for x in train.columns.to_list()[6:]]:\n",
    "  temp = pd.concat([train, dev], copy=True, ignore_index=True)\n",
    "  temp.dropna(inplace=True)\n",
    "  labels = temp['label']\n",
    "  fpr, tpr, thresholds = roc_curve(labels, temp[model])\n",
    "  auc_dict[model] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}\n",
    "  temp2 = temp\n",
    "  for test_language in languages:\n",
    "    temp = temp2.copy()\n",
    "    temp = temp[temp.language == test_language].reset_index(drop=True)\n",
    "    labels = temp['label']\n",
    "    if len(labels) == 0:\n",
    "      fpr, tpr, thresholds = np.array([0, 0]), np.array([0, 0]), np.array([0, 0])\n",
    "    else:\n",
    "      fpr, tpr, thresholds = roc_curve(labels, temp[model])\n",
    "    auc_dict[model][test_language] = {'auc': auc(fpr, tpr), 'th_optim': thresholds[np.argmax(tpr - fpr)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c171f8b-971a-4918-9b3a-097202a3b0bd",
   "metadata": {},
   "source": [
    "# Dev set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e68f789-923d-4c22-96d0-14a32c68f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_th = 'th_optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8bdebd-b5ae-4a12-8b6b-2d42e6f27d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() #'ll', 'entropy', 'rank', 'log-rank', 'llm_deviation'\n",
    "selected = 'll'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "selected = 'rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "selected = 'log-rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "selected = 'llm_deviation'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "s5_dev = s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741bcae4-03ea-44eb-abfc-1f7e7f474007",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 'binoculars'\n",
    "dev['bino'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "s5_dev['bino'] = dev['bino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff874f0f-d4c2-41b3-8e94-6a34cd6fb89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 'falcon'\n",
    "dev['selected1'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]\n",
    "selected = 'mistral'\n",
    "dev['selected2'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(dev['language'], dev[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d433db-f1b4-4cd1-b81f-ae8ea8080bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical part majority voting\n",
    "dev['s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(s5_dev['entropy'], s5_dev['rank'], s5_dev['bino'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd1891c-d668-4ea7-becd-529f9e32b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final majority voting\n",
    "llm2s3 = [1 if x+y+z>=2 else 0 for x,y,z in zip(dev['selected1'], dev['selected2'], dev['s3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa5a5ec-f9c8-4a56-aa44-78042d41074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.91258   0.89250   0.90243      2000\n",
      "           1    0.89481   0.91450   0.90455      2000\n",
      "\n",
      "    accuracy                        0.90350      4000\n",
      "   macro avg    0.90370   0.90350   0.90349      4000\n",
      "weighted avg    0.90370   0.90350   0.90349      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dev['label'], llm2s3, digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01f8ae-c1ad-4cfe-bd15-0de7f31e5235",
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc392bc9-6a89-47db-a91c-fe4efa7d202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"data/subtaskA_multilingual.jsonl\", lines=True)\n",
    "test['language'] = [get_language(text) for text in test['text']]\n",
    "\n",
    "file = \"predictions/s5_test_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "test[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']] = temp[['ll', 'entropy', 'rank', 'log-rank', 'llm_deviation']]\n",
    "file = \"predictions/binoculars_test_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "test['binoculars'] = 1-temp['probs'] #change to higher number represent \"machine\"\n",
    "file = \"predictions/falcon_test_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "test['falcon'] = temp['probs']\n",
    "file = \"predictions/mistral_test_predictions_probs.jsonl\"\n",
    "temp = pd.read_json(file, lines=True)\n",
    "test['mistral'] = temp['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e094cc60-09ba-4bea-9306-b20b8c6d8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_th = 'th_optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec377e82-3dec-4eb7-b244-3d96ccb84f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.DataFrame() #'ll', 'entropy', 'rank', 'log-rank', 'llm_deviation'\n",
    "selected = 'll'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "selected = 'entropy'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "selected = 'rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "selected = 'log-rank'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "selected = 'llm_deviation'\n",
    "s5[selected] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "s5_test = s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0b0e39-af10-4b95-84a1-10c7e33da52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 'binoculars'\n",
    "test['bino'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "s5_test['bino'] = test['bino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07484c36-520a-4a92-8055-5144bb09b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 'falcon'\n",
    "test['selected1'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]\n",
    "selected = 'mistral'\n",
    "test['selected2'] = [1 if (lang in languages) and (prob>=auc_dict[selected][lang][use_th]) else 1 if (lang not in languages) and (prob>=auc_dict[selected][use_th]) else 0 for lang, prob in zip(test['language'], test[selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c44e81d3-5f1b-43af-8d79-bd05f1decd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statistical part majority voting\n",
    "test['s3'] = [1 if x+y+z>=2 else 0 for x,y,z in zip(s5_test['entropy'], s5_test['rank'], s5_test['bino'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24e8fb19-4eae-434a-96bb-1b156fd9a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final majority voting\n",
    "llm2s3 = [1 if x+y+z>=2 else 0 for x,y,z in zip(test['selected1'], test['selected2'], test['s3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33e6c126-57a7-4979-a1e6-5afd240a59e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97519   0.91877   0.94614     20238\n",
      "           1    0.92948   0.97864   0.95342     22140\n",
      "\n",
      "    accuracy                        0.95004     42378\n",
      "   macro avg    0.95233   0.94870   0.94978     42378\n",
      "weighted avg    0.95131   0.95004   0.94994     42378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'label' in test.columns:\n",
    "  print(classification_report(test['label'], llm2s3, digits=5, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0742ada3-2571-43e7-9b3e-57b7ceccc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = llm2s3\n",
    "test[['id', 'label']].to_json(f\"predictions/ensemble-llm2s3_test_predictions.jsonl\", lines=True, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
